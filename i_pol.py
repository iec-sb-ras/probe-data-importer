"""
–ú–æ–¥—É–ª—å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–µ–æ—Ö–∏–º–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel-—Ñ–∞–π–ª–æ–≤ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ RDF-—Ñ–æ—Ä–º–∞—Ç. –¢–∞–∫–∂–µ –º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∂–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –ì—Ä–∞—Ñ–∞ –∑–Ω–∞–Ω–∏–π.

–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:
- –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ XLS-—Ñ–∞–π–ª–æ–≤ —Å –ø–æ–º–æ—â—å—é xlrd
- –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ö–∏–º–∏—á–µ—Å–∫–∏—Ö –∏ –≥–µ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –≤ RDF-—Ç—Ä–∏–ø–ª—ã
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –æ–±—Ä–∞–∑—Ü–∞–º–∏, –∏–∑–º–µ—Ä–µ–Ω–∏—è–º–∏ –∏ –ª–æ–∫–∞—Ü–∏—è–º–∏
- –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ —É–¥–∞–ª—ë–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —á–µ—Ä–µ–∑ HTTP PUT

–û—Å–Ω–æ–≤–Ω—ã–µ –∫–ª–∞—Å—Å—ã:
- ImpState: –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö Excel-–ª–∏—Å—Ç–∞
- Yarki, Kharantsy, Khuzhir: –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –¥–∞–Ω–Ω—ã—Ö

–û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:
- parse_xl(): –ü–∞—Ä—Å–∏–Ω–≥ Excel-—Ñ–∞–π–ª–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞
- upload(): –ó–∞–≥—Ä—É–∑–∫–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ RDF-—Ñ–∞–π–ª–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä
- normURI(): –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä–æ–∫ –¥–ª—è URI
- elem(): –ü–æ–ª—É—á–µ–Ω–∏–µ IRI —ç–ª–µ–º–µ–Ω—Ç–∞ –ø–æ —Å–∏–º–≤–æ–ª—É

–ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã:
- FILES: –°–ª–æ–≤–∞—Ä—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ñ–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞–º –∏ –ª–æ–∫–∞—Ü–∏—è–º
- REGEX-–ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ö–∏–º–∏—á–µ—Å–∫–∏—Ö —Ñ–æ—Ä–º—É–ª –∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
- –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –∏–º–µ–Ω RDF (PT, P, MT, WGS –∏ –¥—Ä.)

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
1. –û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö –≤ FILES
2. –í—ã–∑–æ–≤–∏—Ç–µ parse_xl() –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞
3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ upload() –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

–î–ª—è –∑–∞–º–µ–Ω—ã —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:
1. –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—ã–π –∫–ª–∞—Å—Å, –Ω–∞—Å–ª–µ–¥—É—é—â–∏–π –æ—Ç ImpState (–∏–ª–∏ –µ–≥–æ –ø–æ–¥–∫–ª–∞—Å—Å–æ–≤)
2. –†–µ–∞–ª–∏–∑—É–π—Ç–µ –º–µ—Ç–æ–¥—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π —Ñ–∞–π–ª–æ–≤
3. –û–±–Ω–æ–≤–∏—Ç–µ —Å–ª–æ–≤–∞—Ä—å FILES –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –Ω–æ–≤—ã–º —Ñ–∞–π–ª–∞–º –∏ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞–º
4. –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∞–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –∏ –ª–æ–≥–∏–∫—É –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è

–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
    parse_xl("filename.xls", (Yarki, ["–õ–æ–∫–∞—Ü–∏—è"]))
    upload("output.ttl")

"""

# import pandas as pd
import xlrd
from rdflib import (Graph, Namespace, FOAF, XSD, RDF, RDFS, DCTERMS, URIRef,
                    Literal, BNode)
from rdflib.namespace import WGS, SDO
import os.path
import unicodedata
from enum import Enum
import re
import requests as rq
from requests.auth import HTTPBasicAuth
import base64
import os
from namespace import PT, P, SCHEMA, BIBO, MT, GS, CGI, DBP, DBP_OWL
from pprint import pprint

import pudb

try:
    del os.environ["HTTP_PROXY"]
    del os.environ["HTTPS_PROXY"]
except KeyError:
    pass
try:
    del os.environ["http_proxy"]
    del os.environ["https_proxy"]
except KeyError:
    pass

ONTODIR = "../data/kg"
SUBDIR = "../data/xenolites/"

TARGET = "alrosa.ttl"
TARGETMT = "PeriodicTable.ttl"

EQUIPMENT = "S8 Tiger"
EQUIPMENT_TYPE = "X-Ray fluorescence analysis"

G = Graph(bind_namespaces="rdflib")
GMT = Graph(bind_namespaces="rdflib")
try:
    GMT.parse(location=os.path.join(ONTODIR, 'PeriodicTable.owl'))
except FileNotFoundError:
    pass
GS = [G, GMT]

COMPRE = re.compile(r"^(([A-Z][A-Za-z]{,2}\d{,2})+)(.*?)$")
COMPELRE = re.compile(r"[A-Z][A-Za-z]{,2}\d{,2}")
# r'([A-Z][a-z]*)(\d+(?:\.\d+)?)?'
ELRE = re.compile(r"^([A-Z][A-Za-z]{,2})+(.*)$")

DEGRE = re.compile(r"^(\d{,3})(\D)(\d{,2})(\D)(\d{,2}(\.\d{,2})?)(\D)(.*)$")
# 107¬∞25'28.48"–í
# m = DEGRE.match('107¬∞25\'28.48"–í')
# print(m, m.groups())
# m = DEGRE.match('107¬∞25\'28"–í')
# print(m, m.groups())
# quit()

# spl = COMPELRE.findall("C2H5W8K9OH")
# print(spl)
# spl = COMPELRE.findall("OH")
# print(spl)
# spl = COMPELRE.findall("SiO2")
# print(spl)
# # quit()

COMPOUNDS = {}

for _ in GS:
    _.bind("pt", PT)
    _.bind("pi", P)
    _.bind("mt", MT)
    _.bind("bibo", BIBO)
    _.bind("gs", GS)
    _.bind("cgi", CGI)
    _.bind("dbp", DBP)
    _.bind("dbp_owl", DBP_OWL)
    _.bind("wgs", WGS)
    # _.bind('geo', GEO)

ElToIRI = {}
GeoSite = PT.Site
DataSheet = PT.DataSheet
GeoSample = PT.Sample
GeoMeasure = PT.Measurement
samplerel = PT.sample
PPM = PT.PPM
Percent = PT.Percent
SpatialThing = WGS.SpatialThing
Long = WGS.long
Lat = WGS.lat
IgnitionLosses = PT.IgnitionLosses

G.add((PT.PPM, RDFS.label, Literal("–º–≥/–∫–≥", lang="ru")))
G.add((PT.Percent, RDFS.label, Literal("–ü—Ä–æ—Ü–µ–Ω—Ç", lang="ru")))

for el in GMT.subjects(RDF.type, MT.Element):
    ElToIRI[el.fragment] = el

# print(ElToIRI)


def load_lithology_ontology(graph=None,
                            ttl_file="lithology.ttl",
                            ontodir="./"):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–Ω—Ç–æ–ª–æ–≥–∏—é –ª–∏—Ç–æ–ª–æ–≥–∏–∏ –∏–∑ TTL-—Ñ–∞–π–ª–∞ –≤ RDF-–≥—Ä–∞—Ñ.

    Args:
        graph (Graph): RDF-–≥—Ä–∞—Ñ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –æ–Ω—Ç–æ–ª–æ–≥–∏–∏. –ï—Å–ª–∏ None, —Å–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π.
        ttl_file (str): –ò–º—è TTL-—Ñ–∞–π–ª–∞ —Å –æ–Ω—Ç–æ–ª–æ–≥–∏–µ–π –ª–∏—Ç–æ–ª–æ–≥–∏–∏.
        ontodir (str): –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –æ–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏.

    Returns:
        Graph: –ì—Ä–∞—Ñ —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –æ–Ω—Ç–æ–ª–æ–≥–∏–µ–π –ª–∏—Ç–æ–ª–æ–≥–∏–∏.
    """
    if graph is None:
        graph = Graph(bind_namespaces="rdflib")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
    ttl_path = os.path.join(ontodir, ttl_file)

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–Ω—Ç–æ–ª–æ–≥–∏—é –ª–∏—Ç–æ–ª–æ–≥–∏–∏
        graph.parse(location=ttl_path, format="turtle")
        print(f"‚úì –û–Ω—Ç–æ–ª–æ–≥–∏—è –ª–∏—Ç–æ–ª–æ–≥–∏–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑: {ttl_path}")
        print(f"‚úì –¢—Ä–∏–ø–ª–µ—Ç–æ–≤ –≤ –≥—Ä–∞—Ñ–µ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏: {len(graph)}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–ª–∞—Å—Å—ã –æ–Ω—Ç–æ–ª–æ–≥–∏–∏
        check_ontology_classes(graph)

    except FileNotFoundError:
        print(f"‚ö† –§–∞–π–ª –æ–Ω—Ç–æ–ª–æ–≥–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {ttl_path}")
        print("  –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª lithology.ttl —Å –æ–Ω—Ç–æ–ª–æ–≥–∏–µ–π –ª–∏—Ç–æ–ª–æ–≥–∏–∏")
    except Exception as e:
        print(f"‚úó –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –æ–Ω—Ç–æ–ª–æ–≥–∏–∏: {e}")

    return graph


load_lithology_ontology(G)

def snake_to_camel(snake_str: str, capitalize_first: bool = False) -> str:
    """
    Convert snake_case string to camelCase.

    Args:
        snake_str: The snake_case string to convert
        capitalize_first: If True, returns UpperCamelCase (PascalCase),
                         if False, returns lowerCamelCase (default)

    Returns:
        The converted camelCase string
    """
    if not snake_str:
        return snake_str

    # Split by underscore and capitalize each word except first one
    parts = snake_str.split('_')

    if capitalize_first:
        # UpperCamelCase (PascalCase) - capitalize all words
        return ''.join(part.capitalize() for part in parts)
    else:
        # lowerCamelCase - capitalize all words except first
        return parts[0] + ''.join(part.capitalize() for part in parts[1:])

def capitalize(words):
    orig = " ".join(words.lower().split())
    orig = orig.capitalize()
    return orig

def check_ontology_classes(graph):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤ –æ–Ω—Ç–æ–ª–æ–≥–∏–∏ –ª–∏—Ç–æ–ª–æ–≥–∏–∏ –≤ –≥—Ä–∞—Ñ–µ.

    Args:
        graph (Graph): RDF-–≥—Ä–∞—Ñ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏.
    """
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º namespace –¥–ª—è –ª–∏—Ç–æ–ª–æ–≥–∏–∏ (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –æ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ TTL)
    LITHO = Namespace("http://example.org/geology/")
    graph.bind("litho", LITHO)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–ª–∞—Å—Å—ã
    core_classes = {
        "RockType": "–¢–∏–ø –≥–æ—Ä–Ω–æ–π –ø–æ—Ä–æ–¥—ã",
        "Mineral": "–ú–∏–Ω–µ—Ä–∞–ª",
        "GeologicStructure": "–ì–µ–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞",
        "UltramaficRock": "–£–ª—å—Ç—Ä–∞–º–∞—Ñ–∏—á–µ—Å–∫–∞—è –ø–æ—Ä–æ–¥–∞",
        "MetamorphicRock": "–ú–µ—Ç–∞–º–æ—Ä—Ñ–∏—á–µ—Å–∫–∞—è –ø–æ—Ä–æ–¥–∞"
    }

    print("\n=== –ü–†–û–í–ï–†–ö–ê –ö–õ–ê–°–°–û–í –û–ù–¢–û–õ–û–ì–ò–ò ===")

    for class_name, description in core_classes.items():
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ —Ä–∞–∑–Ω—ã—Ö namespace'–∞—Ö
        class_iris = [
            LITHO[class_name],
            URIRef(f"http://example.org/geology/{class_name}"),
            URIRef(
                f"http://crust.irk.ru/ontology/pollution/terms/1.0/{class_name}"
            )
        ]

        found = False
        for class_iri in class_iris:
            if (class_iri, RDF.type, RDFS.Class) in graph:
                print(f"‚úì –ù–∞–π–¥–µ–Ω –∫–ª–∞—Å—Å: {class_name} ({description})")
                found = True
                break

        if not found:
            print(f"‚ö† –ö–ª–∞—Å—Å –Ω–µ –Ω–∞–π–¥–µ–Ω: {class_name}")


def normURI(s):
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ URI.

    –û—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã –∏ —Ü–∏—Ñ—Ä—ã, –∑–∞–º–µ–Ω—è–µ—Ç –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –Ω–∞ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è.

    Args:
        s (str): –í—Ö–æ–¥–Ω–∞—è —Å—Ç—Ä–æ–∫–∞.

    Returns:
        str: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞.
    """

    r = ""
    for c in s:
        d = unicodedata.category(c)
        if d[0] in ["L", "N"]:
            r += c
        elif len(r) > 0 and r[-1] != "_":
            r += "_"
    return r.rstrip("_")


def elem(name):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç IRI —ç–ª–µ–º–µ–Ω—Ç–∞ –ø–æ –µ–≥–æ —Å–∏–º–≤–æ–ª—É.

    Args:
        name (str): –°–∏–º–≤–æ–ª —ç–ª–µ–º–µ–Ω—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'Fe').

    Returns:
        URIRef: IRI —ç–ª–µ–º–µ–Ω—Ç–∞, –∏–ª–∏ None, –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω.
    """

    p1, p2 = name[:1], name[1:]
    p1 = p1.upper()
    p2 = p2.lower()
    return ElToIRI.get(p1 + p2, None)


PPM_TO_PERCENT = 0.0001  # 1 PPM = 0.0001%

def convert_units(value, from_unit, to_unit='%'):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è –º–µ–∂–¥—É –µ–¥–∏–Ω–∏—Ü–∞–º–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è
    """
    if from_unit == to_unit:
        return value

    conversion_factors = {
        ('PPM', '%'): PPM_TO_PERCENT,
        ('%', 'PPM'): 1 / PPM_TO_PERCENT,
    }

    factor = conversion_factors.get((from_unit, to_unit))
    if factor:
        return value * factor
    else:
        return value  # –ï—Å–ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ

# –°–ª–æ–≤–∞—Ä—å –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–µ–∫—Å—Ç—É—Ä –Ω–∞ IRI –æ–Ω—Ç–æ–ª–æ–≥–∏–∏
ROCK_TEXTURE_MAPPING = {
    # –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–∫—Å—Ç—É—Ä—ã
    'COARSE': PT.CoarseGrainedTexture,
    'COARSE-GRAINED': PT.CoarseGrainedTexture,
    'MEDIUM-GRAINED': PT.MediumGrainedTexture,
    'FINE-GRAINED': PT.FineGrainedTexture,
    'FINE': PT.FineGrainedTexture,

    # –ü–æ—Ä–æ–¥–Ω—ã–µ —Ç–µ–∫—Å—Ç—É—Ä—ã
    'GRANOBLASTIC': PT.GranoblasticTexture,
    'PORPHYROCLASTIC': PT.PorphyroclasticTexture,
    'PORPHYRITIC': PT.PorphyriticTexture,
    'CUMULATE': PT.CumulateTexture,
    'MEGACRYSTALLINE': PT.MegacrystallineTexture,
    'MEGACRYSTIC': PT.MegacrystallineTexture,
    'GRANULAR': PT.GranularTexture,
    'MOSAIC': PT.MosaicTexture,
    'EQUIGRANULAR': PT.EquigranularTexture,
    'SHEARED': PT.ShearedTexture,
    'FOLIATED': PT.FoliatedTexture,
    'FLUIDAL': PT.FluidalTexture,
    'BANDED': PT.BandedTexture,
    'LAMINAR': PT.LaminatedTexture,
    'LAMINATED': PT.LaminatedTexture,

    # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—É—Ä—ã
    'COARSE PORPHYRITIC': PT.CoarsePorphyriticTexture,
    'FINE PORPHYRITIC': PT.FinePorphyriticTexture,
    'COARSE-PORPHYRIC': PT.CoarsePorphyriticTexture,
    'COARSE PORPHYROCLASTIC': PT.CoarsePorphyroclasticTexture,
    'FINE-GRAINED PORPHYROCLASTIC': PT.FineGrainedPorphyroclasticTexture,
    'FINE PORPHYROCLASTIC': PT.FineGrainedPorphyroclasticTexture,
    'MOSAIC-PORPHYROCLASTIC': PT.MosaicPorphyroclasticTexture,
    'GRANOBLASTIC, BANDED': PT.GranoblasticBandedTexture,
    'COARSE GRANOBLASTIC': PT.CoarseGranoblasticTexture,
    'COARSE EQUANT': PT.CoarseEquantTexture,
    'COARSE-EQUANT': PT.CoarseEquantTexture,
    'COARSE TABULAR': PT.CoarseTabularTexture,
    'COARSE-TABULAR': PT.CoarseTabularTexture,
    'MEDIUM- TO COARSE-GRAINED': PT.MediumToCoarseGrainedTexture,
    'FINE- TO MEDIUM-GRAINED': PT.FineToMediumGrainedTexture,
    'FINE- TO COARSE-GRAINED': PT.FineToMediumGrainedTexture,
    'HETEROGRANULAR': PT.HeterogeneousTexture,
    'ALLOTRIOMORPHIC GRANULAR': PT.AllotriomorphicGranularTexture,
    'XENOMORPHIC GRANULAR': PT.XenomorphicGranularTexture,
    'INTERLOCKING': PT.InterlockingTexture,
    'DEFORMED': PT.DeformedTexture,
    'TRANSITIONAL': PT.TransitionalTexture,
    'MYLONITIC': PT.MyloniticTexture,
    'FLUIDAL MOSAIC': PT.FluidalMosaicTexture,

    # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ç–µ–∫—Å—Ç—É—Ä—ã
    'COARSE LAMELLAR': PT.CoarseLamellarTexture,
    'COARSE PROTOGRANULAR': PT.CoarseProtogranularTexture,
    'PROTOGRANULAR': PT.ProtogranularTexture,

    # –°–ª–æ–∂–Ω—ã–µ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—É—Ä—ã
    'LAYERED AND DISRUPTED MOSAIC PORPHYROCLASTIC': PT.LayeredDisruptedMosaicPorphyroclasticTexture,
    'FLUIDAL MOSAIC PORPHYROCLASTIC': PT.FluidalMosaicTexture,
    'MOSAIC-TABULAR TO EQUIGRANULAR': PT.MosaicTexture,
    'HYPAUTOMORPHIC, OPHITIC WITH TRANSITION TO GRANO-LAPIDOBLASTIC': PT.HypautomorphicOphiticTexture,
    'FASCICULATE': PT.FasciculateTexture,
    'POLYGONAL GRANOBLASTIC': PT.PolygonalGranoblasticTexture,

    # –ü–æ—Ä—Ñ–∏—Ä–æ–±–ª–∞—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ–∫—Å—Ç—É—Ä—ã
    'PORPHYROBLASTIC': PT.PorphyroclasticTexture,

    # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ –º–∞–ø–ø–∏–Ω–≥–∏ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π
    'COARSE-PORPHYRIC, PORPHYROCLASTIC, WEAKLY LAMINAR': PT.ComplexTexture,
    'COARSE GRANULAR': PT.CoarseGrainedTexture,
    'COARSE-GRANULAR': PT.CoarseGrainedTexture,
    'MEDIUM-EQUANT': PT.EquigranularTexture,
    'MEDIUM-TABULAR': PT.MediumGrainedTexture,
    'COARSE-EQUANT/TABULAR FOLIATED': PT.CoarseEquantTexture,
    'COARSE-TABULAR FOLIATED': PT.CoarseTabularTexture,

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–ø–µ—á–∞—Ç–æ–∫
    'COASRSE': PT.CoarseGrainedTexture,
    'GRANULOBLASTIC': PT.GranoblasticTexture
}

def get_texture_iri(texture_string):
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º —Ç–µ–∫—Å—Ç—É—Ä—ã –≤ IRI –æ–Ω—Ç–æ–ª–æ–≥–∏–∏.

    Args:
        texture_string (str): –°—Ç—Ä–æ–∫–∞ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º —Ç–µ–∫—Å—Ç—É—Ä—ã –≥–æ—Ä–Ω–æ–π –ø–æ—Ä–æ–¥—ã

    Returns:
        URIRef: IRI —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –∫–ª–∞—Å—Å–∞ —Ç–µ–∫—Å—Ç—É—Ä—ã –∏–ª–∏ PT.ComplexTexture –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
    """
    if not texture_string:
        return None

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä–æ–∫–∏: –≤–µ—Ä—Ö–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä –∏ —É–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
    normalized = ' '.join(texture_string.upper().split())

    # –ü—Ä—è–º–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
    if normalized in ROCK_TEXTURE_MAPPING:
        return ROCK_TEXTURE_MAPPING[normalized]

    # –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π
    for key, value in ROCK_TEXTURE_MAPPING.items():
        if key in normalized:
            return value

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—â–∏–π –∫–ª–∞—Å—Å –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ç–µ–∫—Å—Ç—É—Ä
    return PT.ComplexTexture


class State(Enum):
    NONE = 0
    CLASS = 1
    HEADER = 2
    DATA = 3
    IGNORE = 4
    LOCATION = 5
    DETLIM = 6
    REFERENCES = 7


class ImpState:
    """
    –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel-–ª–∏—Å—Ç–∞.

    –ê—Ç—Ä–∏–±—É—Ç—ã:
    - state: –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    - g: RDF-–≥—Ä–∞—Ñ –¥–ª—è –∑–∞–ø–∏—Å–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    - locations: –°–ø–∏—Å–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ª–æ–∫–∞—Ü–∏–π

    –ú–µ—Ç–æ–¥—ã:
    - proc_comp(): –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ö–∏–º–∏—á–µ—Å–∫–∏—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    - proc_loc(): –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π –ª–æ–∫–∞—Ü–∏–∏
    - r(): –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–æ–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    - c(): –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π —è—á–µ–π–∫–∏

    –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ª–∏—Å—Ç–∞ Excel.

    Attributes:
        state (State): –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏.
        instr (bool): –§–ª–∞–≥, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π, —á—Ç–æ —Ç–µ–∫—É—â–∞—è —Å—Ç—Ä–æ–∫–∞ - –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è.
        prev_class: –ü—Ä–µ–¥—ã–¥—É—â–∏–π –∫–ª–∞—Å—Å.
        cls (dict): –°–ª–æ–≤–∞—Ä—å –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –∫–æ–ª–æ–Ω–æ–∫.
        header (dict): –°–ª–æ–≤–∞—Ä—å –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –¥–ª—è –∫–æ–ª–æ–Ω–æ–∫.
        dsiri: IRI –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö.
        g (Graph): RDF-–≥—Ä–∞—Ñ.
        sample: –¢–µ–∫—É—â–∏–π –æ–±—Ä–∞–∑–µ—Ü.
        locations (list): –°–ø–∏—Å–æ–∫ –ª–æ–∫–∞—Ü–∏–π.
        sample_col (int): –ù–æ–º–µ—Ä –∫–æ–ª–æ–Ω–∫–∏ —Å –æ–±—Ä–∞–∑—Ü–∞–º–∏.
        loc_fence (int): –ì—Ä–∞–Ω–∏—Ü–∞ –¥–ª—è –ª–æ–∫–∞—Ü–∏–π.
        dlims (dict): –°–ª–æ–≤–∞—Ä—å –ø—Ä–µ–¥–µ–ª–æ–≤ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è.

    Methods:
        proc_comp: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ö–∏–º–∏—á–µ—Å–∫–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏–ª–∏ —ç–ª–µ–º–µ–Ω—Ç.
        proc_locs: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ª–æ–∫–∞—Ü–∏–π.
        proc_loc: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω—É –ª–æ–∫–∞—Ü–∏—é.
        belongs: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏.
        data: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ DATA.
        ign: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ IGNORE.
        r: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—Ç—Ä–æ–∫—É.
        c: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —è—á–µ–π–∫—É –≤ —Ä–µ–∂–∏–º–µ –¥–∞–Ω–Ω—ã—Ö.
        h: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —è—á–µ–π–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–∞.
        hc: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —è—á–µ–π–∫—É –∫–ª–∞—Å—Å–∞.
    """

    _sample_iri_ = samplerel
    _belongs_iri_ = PT["location"]
    _start_state_ = None

    def __init__(self, graph, datasetIRI, locations=None, **kwargs):
        self.state = self._start_state_
        self.instr = False
        self.prev_class = None
        self.cls = {}
        self.header = {}
        self.dsiri = datasetIRI  # TODO: Add type GelologicalSite!!
        self.g = graph
        self.sample = None
        self.locations = []
        self.sample_col = None
        self.proc_locs(locations)
        self.loc_fence = len(self.locations)
        self.dlims = {}
        self.kwargs = kwargs
        self.non_iso = {}
        self.measurements = {}
        self.analysis = None
        self.fls = {}

    def proc_value(self, value):
        if isinstance(value, str):
            sv = value.strip()
            return sv
        sn = value
        if isinstance(sn, float) and sn.is_integer():
            return int(sn)
        return sn

    def add(self, triple):
        # print("T:{}".format(triple))
        self.g.add(triple)

    def proc_comp(self, names, value, delim=False):
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ö–∏–º–∏—á–µ—Å–∫–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏–ª–∏ —ç–ª–µ–º–µ–Ω—Ç —Å 	—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö (PPM -> %)

        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        - names: –ö–æ—Ä—Ç–µ–∂ (–ø–æ–ª–µ, –∏–º—è_–ø–æ–ª—è)
        - value: –ó–Ω–∞—á–µ–Ω–∏–µ —è—á–µ–π–∫–∏
        - delim: –§–ª–∞–≥ –ø—Ä–µ–¥–µ–ª–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
                """

        uvalue = str(value).upper().strip()
        if isinstance(value, str):
            value = value.strip()
        if "N.A." in uvalue:
            return
        dl = None
        ovalue = value  # Original value
        if "<" in uvalue:
            dl = value.lstrip("<").strip()
            value = dl

        name, fieldname = names
        name = name.strip()
        mo = COMPRE.match(name)
        add = self.add

        rel = PT[normURI(name)]

        def finish():
            if self.analysis and not delim:
                # print(type(ovalue))
                ### print("->{}->{}".format(rel, repr(ovalue)))
                add((self.analysis, rel, Literal(ovalue)))

        def degs(v):
            if isinstance(v, float):
                return v
            # 107¬∞25'28.48"–í
            m = DEGRE.match(v)
            if m is None:
                return v
            d, _, m, _, s, _, _, dir = m.groups()
            d, m, s = [float(v) for v in [d, m, s]]
            d += m / 60.0
            d += s / 3600.0
            return d

        def unit(m, rupper):
            if "PPM" in rupper:
                add((m, PT.unit, PPM))
            elif "INT" in rupper:
                add((m, PT.unit, P.Int))
            elif "%" in fieldname:
                add((m, PT.unit, Percent))
            else:
                add((m, PT.unit, P.UnknowUnit))

        def create_measurement_with_normalization(m, measurement_value, unit_type, rupper):
            """–°–æ–∑–¥–∞–µ—Ç –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏"""
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            if dl is None:
                add((m, PT.value, Literal(measurement_value)))

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
            if unit_type == 'PPM':
                add((m, PT.unit, PPM))
                # üî• –î–û–ë–ê–í–õ–Ø–ï–ú –ù–û–†–ú–ê–õ–ò–ó–û–í–ê–ù–ù–û–ï –ó–ù–ê–ß–ï–ù–ò–ï (PPM -> %)
                if not delim and isinstance(measurement_value, (int, float)):
                    normalized_value = measurement_value * 0.0001  # PPM to %
                    add((m, PT.normalizedValue, Literal(normalized_value)))
                    add((m, PT.normalizedUnit, Percent))
            elif unit_type == '%':
                add((m, PT.unit, Percent))
            elif unit_type == 'INT':
                add((m, PT.unit, P.Int))
            else:
                add((m, PT.unit, P.UnknowUnit))

        if isinstance(value, float) and value.is_integer():
            value = int(value)
        if name in ["–ü–ü–ü", "–ø–ø–ø"]:
            rel = PT.il  # ignition losses
            m = BNode()
            add((self.analysis, PT.measurement, m))
            add((m, PT.value, Literal(value)))
            add((m, RDF.type, GeoMeasure))
            add((m, RDF.type, IgnitionLosses))
            u = name.upper()
            unit(m, u)
            return

        if mo is None:
            if name == "—Å_—à":
                rel = Lat
                ovalue = degs(ovalue)
            if name == "–≤_–¥":
                rel = Long
                ovalue = degs(ovalue)
            if name in ["sku", "–Ω–æ–º–µ—Ä"]:
                rel = SDO.sku
                if isinstance(ovalue, float):
                    ovalue = int(ovalue)
            finish()
            return
        else:
            comp = mo.group(1)
            rest = mo.group(3)
            rc = COMPELRE.findall(comp)
            el1 = rc[0]
            el = ELRE.match(el1).group(1)
            eliri = elem(el)

        if eliri is None:  # This is not a compound
            if self._field_map_ is not None:
                f = self._field_map_.get(fieldname, None)
                if f is None:
                    f = self._field_map_.get(name, None)
                if f is None:
                    finish()
                else:
                    f(self, value, names=names, delim=delim)
            return

        def make_detlim():
            m = BNode()
            add((self.dsiri, PT.detectionLimit, m))
            add((m, RDF.type, PT.DetectionLimit))
            return m

        m = None

        if self.analysis and not delim:
            m = BNode()
            add((self.analysis, PT.measurement, m))
            add((m, RDF.type, GeoMeasure))
        if delim:
            m = make_detlim()

        rupper = rest.upper()

        if dl is None:
            add((m, PT.value, Literal(value)))
            unit(m, rupper)

        # üî• –°–û–ó–î–ê–ï–ú –ò–ó–ú–ï–†–ï–ù–ò–ï –° –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–ï–ô
        create_measurement_with_normalization(m, value, unit_type, rupper)

        def finish_dl(e, m):
            if delim:
                self.dlims[e] = m
            if dl is not None:
                dlm = self.dlims.get(e, None)
                if dlm is not None:
                    add((m, PT.value, dlm))
                else:
                    # m is description, connected to a sample
                    md = make_detlim()
                    # –î–ª—è –ø—Ä–µ–¥–µ–ª–æ–≤ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Ç–æ–∂–µ –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é
                    add((md, PT.value, Literal(value)))
                    add((md, RDF.type, GeoMeasure))
                    unit(md, rupper)
                    create_measurement_with_normalization(md, value, unit_type, rupper)
                    self.dlims[e] = md
                    add((m, PT.value, md))

        if len(rc) > 1 or el1 != el:  # Compound, e.g. oxide
            compname = "compound-" + normURI(comp)
            cb = COMPOUNDS.get(compname, None)
            if cb is None:
                cb = PT[compname]
                add((cb, RDF.type, PT.Compound))
                add((cb, PT.Formula, Literal(comp)))
                add((cb, RDFS.label, Literal(comp)))
                COMPOUNDS[compname] = cb
            add((m, PT.compound, cb))

            finish_dl(comp, m)

        elif len(rc) == 1 and el1 == el and eliri is not None:
            add((m, MT.element, eliri))
            finish_dl(el, m)
        else:
            print("#!ERROR unknown combination of {}, and {}=?={}: {}.".format(
                rc, el1, el, eliri))
            quit()

        if "TOT" in rupper or "–û–ë–©" in rupper:
            add((m, PT.total, Literal(True)))

    def proc_locs(self, locations):
        if locations is None:
            return
        for loc in locations:
            self.proc_loc(loc)

    def proc_loc(self, location):
        location = location.strip()
        uriloc = P[normURI(location)]
        locs = self.locations
        if locs:
            prev = locs[-1]
            self.belongs(uriloc, prev)
        add = self.add
        add((uriloc, RDFS.label, Literal(location, lang="ru")))
        add((uriloc, RDF.type, GeoSite))
        self.locations.append(uriloc)

    def belongs(self, obj, location=None):
        if location is None:
            if len(self.locations) > 0:
                location = self.locations[-1]
            else:
                return  # None to belong to
        add = self.add
        # print(self.locations)
        add((obj, self._belongs_iri_, location))

    def data(self):
        return self.state == State.DATA

    def ign(self):
        return self.state == State.IGNORE

    def row(self, row, rx):
        self.instr = False
        self.sample = None

        f = row[0]
        fs = f.value

        if f.ctype == xlrd.XL_CELL_TEXT:
            fss = fs.strip()
            if fss.startswith("#"):
                fss = fss.lstrip("#")
                try:
                    self.state = State[fss]
                except KeyError as k:
                    print("#! ERROR Key: {}".format(k))
                    quit()
                self.instr = True
        if self.ign() or self.instr:
            return

        detlim = self.state == State.DETLIM
        if self.data() or detlim:
            if self.sample is None:
                self.c(row[self.sample_col], rx, self.sample_col, sheet_row = row, detlim=delim)
            for i, cell in enumerate(row):
                self.c(cell, rx, i, detlim=delim, sheet_row=row)
            return

        if self.state == State.HEADER:
            for i, cell in enumerate(row):
                self.h(cell, rx, i)
            return

        if self.state == State.CLASS:
            self.prev_class = None
            for i, cell in enumerate(row):
                self.hc(cell, rx, i)
            return

        if self.state == State.LOCATION:
            for cell in row:
                if cell.ctype == xlrd.XL_CELL_TEXT:
                    if len(self.locations) > self.loc_fence:
                        self.locations.pop()
                    loc = cell.value.strip()
                    self.proc_loc(loc)

    def c(self, cell, row, col, sheet_row, detlim=False):
        if cell.ctype in [xlrd.XL_CELL_EMPTY, xlrd.XL_CELL_BLANK]:
            return
        try:
            field, fieldname = self.header[col]
        except KeyError as k:
            print("#! ERROR header key {} not in {} row: {}".format(
                k, self.header, row))
            # quit()
            return

        prt = self.cls.get(col, "")
        if "%" in prt and "PPM" not in field:
            prt = "_%"
        elif "PPM" in prt and "%" not in field:
            prt = "_PPM"
        else:
            prt = ""

        add = self.add
        ds = self.dsiri
        val = cell.value
        if field == self._sample_iri_:
            if isinstance(val, str):
                name = val.replace(" ", "")
            else:
                if isinstance(val, float):
                    if val.is_integer():
                        name = str(int(val))
                    else:
                        name = "{}".format(val)
                else:
                    name = "{}".format(val)
            add((ds, self._sample_iri_, self.sample))
            add((self.sample, RDF.type, GeoSample))
            add((self.sample, RDFS.label, Literal(name)))
            # add((self.sample, RDF.type, SpatialThing))
            self.belongs(self.sample)
        elif self.sample is not None:
            self.proc_comp((field + prt, fieldname + prt), cell.value)
        elif detlim:
            self.proc_comp((field + prt, fieldname + prt), cell.value, detlim)
        else:
            print("#! ERROR: nowhere to store {} R:{} C:{}\n#!{}".format(
                cell, row, col, self.header))
            quit()

    def h(self, cell, row, col):
        if cell.ctype in [xlrd.XL_CELL_EMPTY, xlrd.XL_CELL_BLANK]:
            return
        orig = str(cell.value)
        name = normURI(orig)
        if name in self._sample_names_:
            name = self._sample_iri_
            self.sample_col = col
        self.header[col] = (name, orig)

    def hc(self, cell, row, col):
        if cell.ctype in [xlrd.XL_CELL_EMPTY, xlrd.XL_CELL_BLANK]:
            if self.prev_class is None:
                return
            orig, name = self.prev_class
        else:
            orig = str(cell.value).replace("–º–≥/–∫–≥", "PPM")
            name = normURI(orig)
        self.cls[col] = orig
        self.prev_class = orig, name


class Yarki(ImpState):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞ –Ø—Ä–∫–∏."""
    _sample_names_ = ["Sample", "–ü–æ–ª–µ–≤–æ–π", "sample"]


class Kharantsy(ImpState):
    _sample_names_ = ["–ù–æ–º–µ—Ä_–ø—Ä–æ–±—ã"]


class Khuzhir(Kharantsy):
    pass


class Alrosa(ImpState):

    _start_state_ = State.HEADER
    _sample_names_ = ['SAMPLE_NAME']
    _sheet_names_ = [0]

    def reffield(self, value):
        try:
            cnum, reference = value.split(maxsplit=1)
        except ValueError:
            cnum = value.strip()
            reference = ""
        num = cnum.strip().lstrip("[").rstrip("]")
        refURI = P["ref-{}".format(num)]
        reference = reference.strip()
        if not reference:
            reference = None
        return refURI, reference

    def row(self, row, rx):
        self.instr = False
        self.sample = None
        self.analysis = None
        if self.state == State.HEADER:
            for i, cell in enumerate(row):
                self.h(cell, rx, i)
            self.state = State.DATA
            print("HEADER:{}".format(self.header))
            return
        c0 = row[0]
        v0 = str(c0.value).strip()
        if v0.startswith("#REFERENCES"):
            self.state = State.REFERENCES
            return
        if self.state == State.DATA:
            if self.sample is None and self.sample_col is not None:
                self.c(row[self.sample_col], rx, self.sample_col, sheet_row=row)
            for i, cell in enumerate(row):
                if i == self.sample_col:
                    continue
                self.c(cell, rx, i, sheet_row=row)
        if self.state == State.REFERENCES:
            refURI, reference = self.reffield(v0)
            assert (reference is not None)
            self.add((refURI, RDF.type, BIBO["AcademicArticle"]))
            self.add((refURI, RDFS.label, Literal(reference)))

    def c(self, cell, row, col, sheet_row, detlim=False):
        if cell.ctype in [xlrd.XL_CELL_EMPTY, xlrd.XL_CELL_BLANK]:
            return
        try:
            field, fieldname = self.header[col]
        except KeyError as k:
            print("#! ERROR header key {} not in {} row: {}".format(
                k, self.header, row))
            # quit()
            return

        # prt = self.cls.get(col, "")
        prt = ""
        if "%" in prt and "PPM" not in field:
            prt = "_%"
        elif "PPM" in prt and "%" not in field:
            prt = "_PPM"
        else:
            prt = ""

        add = self.add
        ds = self.dsiri
        val = cell.value
        if field == self._sample_iri_:
            if isinstance(val, str):
                name = val.replace(" ", "")
            else:
                if isinstance(val, float):
                    if val.is_integer():
                        name = str(int(val))
                    else:
                        name = "{}".format(val)
                else:
                    name = "{}".format(val)
            name = name.strip().lstrip('samp.')
            name_orig = name
            name = name.replace("^A", "")
            name = name.replace("^D", "")
            name = name.replace("^M", "")
            name = name.replace("/", "-sl-")
            name = name.replace("?", "-q-")
            name = name.strip("¬†")
            name = name.lstrip()
            if name_orig!=name:
                # print("PROBLEMATIC:{} ({})".format(name, name_orig))
                ns = self.non_iso.setdefault(name, [])
                ns.append(name_orig)
            samplename = 'sample-'+name
            sample_iri = P[samplename]
            meas = self.measurements
            mlist = meas.setdefault(sample_iri, [])
            self.analysis = P['analysis-{}-{}'.format(len(mlist)+1, samplename)]
            mlist.append(self.analysis)
            # if (sample_iri, RDF.type, PT.GeoSample) in self.g:
            #     print("Double: {} \n ROW:{}".format())
            #     quit
            self.sample = sample_iri
            add((ds, self._sample_iri_, self.sample))
            add((self.sample, RDF.type, GeoSample))
            add((self.sample, RDFS.label, Literal(name)))
            add((self.sample, PT.hasAnalysis, self.analysis))

            # add((self.sample, RDF.type, SpatialThing))
            self.belongs(self.sample)
        elif field == "CITATION":
            assert isinstance(val, str)
            refURI, reference = self.reffield(val)
            add((self.sample, BIBO.cites, refURI))
        elif field == "LOCATION":
            assert isinstance(val, str)
            locations = val.split("/")
            locations = [l.strip() for l in locations]

            for location in locations:
                if location not in self.fls:
                    location_bnode = BNode()  # –°–æ–∑–¥–∞–µ–º BNode –¥–ª—è –∫–∞–∂–¥–æ–π –ª–æ–∫–∞—Ü–∏–∏
                    self.fls[location] = location_bnode

                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ª–æ–∫–∞—Ü–∏–∏
                    add((location_bnode, RDF.type, SCHEMA.Place))
                    add((location_bnode, RDFS.label, Literal(location)))

                    # üî• –î–æ–±–∞–≤–ª—è–µ–º –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ BNode
                    self._add_location_metadata(location_bnode, sheet_row)
                else:
                    location_bnode = self.fls[location]
                # –°–≤—è–∑—ã–≤–∞–µ–º –æ–±—Ä–∞–∑–µ—Ü —Å –ª–æ–∫–∞—Ü–∏–µ–π
                add((self.sample, SCHEMA.fromLocation, location_bnode))

        # üî• –ù–û–í–û–ï: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        elif field in ["LATITUDE_MIN", "LATITUDE_MAX", "LONGITUDE_MIN", "LONGITUDE_MAX",
                      "LOCATION_COMMENT", "LAND_SEA_SAMPLING", "ELEVATION_MIN", "ELEVATION_MAX"]:
            # –≠—Ç–∏ –ø–æ–ª—è –±—É–¥—É—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –≤ _add_location_metadata
            pass

        # üî• –ù–û–í–û–ï: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–≤–æ–π—Å—Ç–≤
        elif field == "LOCATION_COMMENT":
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ BNode –ª–æ–∫–∞—Ü–∏–∏
            self._current_location_comment = val

        elif field == "LAND_SEA_SAMPLING":
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∏–ø–∞ –æ—Ç–±–æ—Ä–∞ –ø—Ä–æ–±
            self._process_sampling_type(val)

        elif field == "ALTERATION":
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–ª—å—Ç–µ—Ä–∞—Ü–∏–∏
            self._process_alteration(val)

        elif field == "ROCK_TEXTURE":
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç—É—Ä—ã —á–µ—Ä–µ–∑ –Ω–∞—à—É —Å–∏—Å—Ç–µ–º—É
            self._process_rock_texture(val)

        elif field == "ROCK_NAME":
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ—Ä–æ–¥—ã
            self._process_rock_name(val)

        elif field == "TECTONIC_SETTING":
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Ç–æ–Ω–∏—á–µ—Å–∫–æ–π –æ–±—Å—Ç–∞–Ω–æ–≤–∫–∏
            self._process_tectonic_setting(val)

        elif field == "MINERAL":
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–∏–Ω–µ—Ä–∞–ª–∞
            self._process_mineral(val)

        elif field == "PRIMARY_SECONDARY":
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∏–ø–∞ –≤–∫–ª—é—á–µ–Ω–∏—è
            self._process_inclusion_type(val)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ö–∏–º–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö (—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥)
        elif self.sample is not None:
            self.proc_comp((field + prt, fieldname + prt), cell.value)
        elif detlim:
            self.proc_comp((field + prt, fieldname + prt), cell.value, detlim)
        else:
            value = self.proc_value(cell.value)
            if value is not None and self.kwargs['sheetName'] != 'References':
                print("#! ERROR: nowhere to store {} R:{} C:{}\n#!{}".format(
                    cell, row, col, self.header))
                quit()

    def _add_location_metadata(self, location_bnode, row):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ª–æ–∫–∞—Ü–∏–∏ –≤ BNode"""
        add = self.add

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å—Ç—Ä–æ–∫–∏
        location_data = {}

        for col, (field, fieldname) in self.header.items():
            cell = row[col]
            if cell.ctype in [xlrd.XL_CELL_EMPTY, xlrd.XL_CELL_BLANK]:
                continue

            val = cell.value

            # üî• –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏ –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
            if field == "LATITUDE_MIN":
                location_data['lat_min'] = val
                add((location_bnode, PT.latitudeMin, Literal(val)))
            elif field == "LATITUDE_MAX":
                location_data['lat_max'] = val
                add((location_bnode, PT.latitudeMax, Literal(val)))
            elif field == "LONGITUDE_MIN":
                location_data['long_min'] = val
                add((location_bnode, PT.longitudeMin, Literal(val)))
            elif field == "LONGITUDE_MAX":
                location_data['long_max'] = val
                add((location_bnode, PT.longitudeMax, Literal(val)))
            elif field == "LOCATION_COMMENT":
                add((location_bnode, PT.locationComment, Literal(val)))
            elif field == "ELEVATION_MIN":
                add((location_bnode, PT.elevationMin, Literal(val)))
            elif field == "ELEVATION_MAX":
                add((location_bnode, PT.elevationMax, Literal(val)))

        # üî• –°–æ–∑–¥–∞–µ–º —Ç–æ—á–∫—É/–ø–æ–ª–∏–≥–æ–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
        self._create_geometry(location_bnode, location_data)

    def _create_geometry(self, location_bnode, location_data):
        """–°–æ–∑–¥–∞–µ—Ç –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π –æ–±—ä–µ–∫—Ç –¥–ª—è –ª–æ–∫–∞—Ü–∏–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–Ω—Ç–æ–ª–æ–≥–∏–µ–π"""
        add = self.add

        # üî• –£–∫–∞–∑—ã–≤–∞–µ–º —Ç–∏–ø –¥–ª—è BNode –ª–æ–∫–∞—Ü–∏–∏
        add((location_bnode, RDF.type, PT.GeoBounds))

        # –ï—Å–ª–∏ –µ—Å—Ç—å –∏ min –∏ max –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã - —Å–æ–∑–¥–∞–µ–º bounding box
        if all(k in location_data for k in ['lat_min', 'lat_max', 'long_min', 'long_max']):
            bbox = BNode()
            add((location_bnode, SCHEMA.geo, bbox))
            add((bbox, RDF.type, SCHEMA.GeoShape))
            add((bbox, SCHEMA.box, Literal(
                f"{location_data['lat_min']} {location_data['long_min']} "
                f"{location_data['lat_max']} {location_data['long_max']}"
            )))

        # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–∞ –ø–∞—Ä–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç - —Å–æ–∑–¥–∞–µ–º —Ç–æ—á–∫—É
        elif 'lat_min' in location_data and 'long_min' in location_data:
            point = BNode()
            add((location_bnode, WGS.location, point))
            add((point, RDF.type, WGS.Point))
            add((point, WGS.lat, Literal(location_data['lat_min'])))
            add((point, WGS.long, Literal(location_data['long_min'])))

    def _process_sampling_type(self, value):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∏–ø–∞ –æ—Ç–±–æ—Ä–∞ –ø—Ä–æ–±"""
        if not hasattr(self, 'sample') or self.sample is None:
            return

        value = str(value).strip().lower()
        if value in ['subaerial', 'submarine', 'underground']:
            self.add((self.sample, PT.samplingEnvironment, PT[value]))
        else:
            # –°–æ–∑–¥–∞–µ–º –ª–∏—Ç–µ—Ä–∞–ª –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ç–∏–ø–æ–≤
            self.add((self.sample, PT.samplingEnvironment, Literal(value)))

    def _process_alteration(self, value):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–ª—å—Ç–µ—Ä–∞—Ü–∏–∏ –ø–æ—Ä–æ–¥—ã —Å —Å–æ–∑–¥–∞–Ω–∏–µ–º —Å—É—â–Ω–æ—Å—Ç–µ–π"""
        if not hasattr(self, 'sample') or self.sample is None:
            return

        if isinstance(value, str) and value.strip():
            alterations = [alt.strip().lower() for alt in value.split(",")]
            for alteration in alterations:
                if alteration:
                    alt_iri = PT[normURI(alteration)]

                    # üî• –°–æ–∑–¥–∞–µ–º —Å—É—â–Ω–æ—Å—Ç—å AlterationType –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                    if (alt_iri, RDF.type, PT.AlterationType) not in self.g:
                        self.add((alt_iri, RDF.type, PT.AlterationType))
                        self.add((alt_iri, RDFS.label, Literal(alteration.capitalize())))

                    self.add((self.sample, PT.hasAlteration, alt_iri))

    def _process_rock_texture(self, value):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç—É—Ä—ã –ø–æ—Ä–æ–¥—ã —á–µ—Ä–µ–∑ –Ω–∞—à—É —Å–∏—Å—Ç–µ–º—É"""
        if not hasattr(self, 'sample') or self.sample is None:
            return

        if isinstance(value, str) and value.strip():
            texture_iri = get_texture_iri(value)
            if texture_iri:
                self.add((self.sample, PT.rockTexture, texture_iri))
            else:
                # Fallback: —Å–æ–∑–¥–∞–µ–º –ª–∏—Ç–µ—Ä–∞–ª
                self.add((self.sample, PT.rockTexture, Literal(value)))

    def _process_rock_name(self, value):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ—Ä–æ–¥—ã"""
        if not hasattr(self, 'sample') or self.sample is None:
            return

        if isinstance(value, str) and value.strip():
            rocks = [rock.strip().lower() for rock in value.split(",")]
            for rock in rocks:
                if rock:
                    if rock in ['xenolith']:
                        self.add((self.sample, PT.geologicalStructure, PT[rock]))
                    elif rock in ['megacryst']:
                        self.add((self.sample, PT.geologicUnit, PT[rock]))
                    elif rock in COMMON_MINERALS:  # –ü—Ä–µ–¥–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –º–∏–Ω–µ—Ä–∞–ª–æ–≤
                        self.add((self.sample, PT.mineral, PT[rock]))
                    else:
                        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —ç—Ç–æ —Ç–∏–ø –ø–æ—Ä–æ–¥—ã
                        rock_iri = PT[normURI(rock)]
                        self.add((rock_iri, RDF.type, PT.RockType))
                        self.add((rock_iri, RDFS.label, Literal(rock.capitalize())))
                        self.add((self.sample, PT.rockType, rock_iri))

    def _process_tectonic_setting(self, value):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Ç–æ–Ω–∏—á–µ—Å–∫–æ–π –æ–±—Å—Ç–∞–Ω–æ–≤–∫–∏"""
        if not hasattr(self, 'sample') or self.sample is None:
            return

        if isinstance(value, str) and value.strip():
            orig = capitalize(value)
            val_norm = value.strip().lower()
            val_iri = normURI(val_norm)
            setting_iri = PT[val_iri]
            self.add((setting_iri, RDF.type, PT.TectonicSetting))
            self.add((setting_iri, RDFS.label, Literal(orig)))
            self.add((self.sample, PT.tectonicSetting, setting_iri))

    def _process_mineral(self, value):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –º–∏–Ω–µ—Ä–∞–ª–∞"""
        if not hasattr(self, 'sample') or self.analysis is None:
            return

        if isinstance(value, str) and value.strip():
            minerals = [mineral.strip().lower() for mineral in value.split(",")]
            for mineral in minerals:
                if mineral:
                    mineral_iri = PT[normURI(mineral)]
                    self.add((mineral_iri, RDF.type, PT.Mineral))
                    self.add((mineral_iri, RDFS.label, Literal(mineral.capitalize())))
                    self.add((self.analysis, PT.mineral, mineral_iri))

    def _process_inclusion_type(self, value):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∏–ø–∞ –≤–∫–ª—é—á–µ–Ω–∏—è"""
        if not hasattr(self, 'sample') or self.sample is None:
            return

        if isinstance(value, str) and value.strip():
            value = value.strip().lower()
            if "primary" in value:
                inclusion_type = "Primary"
            elif "secondary" in value:
                inclusion_type = "Secondary"
            else:
                inclusion_type = "Primary"  # –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

            self.add((self.sample, PT.inclusion, PT[inclusion_type]))

    def fCITATION(self, value, **kw):
        add = self.add

        add((self.sample, DCTERMS.bibliographicCitation, Literal(value)))

    _field_map_ = {
        'CITATION': fCITATION,
    }

 # üî• –ü—Ä–µ–¥–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
COMMON_MINERALS = {
    "garnet", "spinel", "olivine", "clinopyroxene", "orthopyroxene",
    "ilmenite", "phlogopite", "amphibole", "biotite", "chromite",
    "kyanite", "diamond", "graphite", "corundum", "sanidine",
    "enstatite", "fassaite"
}

COMMON_ROCK_TYPES = {
    "lherzolite", "harzburgite", "peridotite", "wehrlite", "dunite",
    "websterite", "clinopyroxenite", "orthopyroxenite", "pyroxenite",
    "eclogite"
}
#

class Alrosa_Xenolites(Alrosa):
    pass


FILES = {
    '–ë–î georock corr_MVG.xls': (Alrosa_Xenolites, {
        'pages': (0, 1)
    }),
    '–ë–î –≥—Ä–∞–Ω–∞—Ç—ã –∏–∑ –∫—Å–µ–Ω–æ–ª–∏—Ç–æ–≤.xls': (Alrosa_Xenolites, {
        'pages': []
    })
}


def parse_sheet(sh, sheetIRI, sheetName, comp):
    # print("Cell D30 is {0}".format(sh.cell_value(rowx=29, colx=3)))
    constr, locs = comp
    st = constr(G, sheetIRI, locations=locs, sheetName=sheetName, sheet=sh)
    G.add((sheetIRI, RDF.type, DataSheet))
    sheetName = sheetName.replace(".xls_", ", ")
    G.add((sheetIRI, RDFS.label, Literal(sheetName)))
    print("Parsing sheet: {}".format(sheetName))
    for rx in range(sh.nrows):
        st.row(sh.row(rx), rx)
    #print("PROBLEMATICS:")
    #pprint(st.non_iso)


def parse_xl(file, comp):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —É–∫–∞–∑–∞–Ω–Ω—ã–π Excel-—Ñ–∞–π–ª.

    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
    - file: –ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    - comp: –ö–æ—Ä—Ç–µ–∂ (–∫–ª–∞—Å—Å-–æ–±—Ä–∞–±–æ—Ç—á–∏–∫, —Å–ø–∏—Å–æ–∫_–ª–æ–∫–∞—Ü–∏–π)
    """

    print("# FILE: {} at {}".format(file, SUBDIR))
    pathfile = os.path.join(SUBDIR, file)
    # df = pd.read_excel(pathfile)
    wb = xlrd.open_workbook(pathfile)
    print("# Sheet names: {}".format(wb.sheet_names()))
    for sheet_no, sheet in enumerate(wb.sheet_names()):
        print("# Wb: {}, sheet: {}".format(file, sheet))
        sh = wb.sheet_by_name(sheet)
        sheetname = normURI(file + "_" + sheet)
        print("{0} {1} {2}".format(sh.name, sh.nrows, sh.ncols))
        constr, _ = comp
        whole_name = file + "_" + sheet
        if hasattr(constr, '_sheet_names_'):
            if sheet in constr._sheet_names_:
                parse_sheet(sh, P[sheetname], whole_name, comp)
            elif sheet_no in constr._sheet_names_:
                parse_sheet(sh, P[sheetname], whole_name, comp)
        else:
            parse_sheet(sh, P[sheetname], whole_name, comp)


def update(g):
    # qres=g.query('''
    # PREFIX pt: <http://crust.irk.ru/ontology/pollution/terms/1.0/>
    # PREFIX p: <http://crust.irk.ru/ontology/pollution/1.0/>
    # PREFIX mt: <http://www.daml.org/2003/01/periodictable/PeriodicTable#>
    # PREFIX wgs: <https://www.w3.org/2003/01/geo/wgs84_pos#>
    # SELECT ?sample
    # WHERE {
    #     ?sample a pt:GeologicalSample .
    #     ?sample wgs:long ?long .
    #     ?sample wgs:lat ?lat .
    # }
    # ''')
    # for row in qres:
    #     print(row)

    g.update("""
    PREFIX pt: <http://crust.irk.ru/ontology/pollution/terms/1.0/>
    PREFIX p: <http://crust.irk.ru/ontology/pollution/1.0/>
    PREFIX mt: <http://www.daml.org/2003/01/periodictable/PeriodicTable#>
    PREFIX wgs: <https://www.w3.org/2003/01/geo/wgs84_pos#>
    DELETE {
        ?sample a wgs:SpatialThing .
        ?sample wgs:long ?long .
        ?sample wgs:lat ?lat .
    }
    INSERT {
        ?sample wgs:location _:l .
        _:l a wgs:Point .
        _:l wgs:long ?long .
        _:l wgs:lat ?lat .
    }
    WHERE {
        ?sample a pt:Sample .
        ?sample wgs:long ?long .
        ?sample wgs:lat ?lat .
    }
    """)


PUTURL = "http://ktulhu.isclan.ru:8890/DAV/home/{user}/rdf_sink/{name}"
USER = base64.b64decode("bG9hZGVyCg==").decode("utf8").strip()
CRED = base64.b64decode("bG9hZGVyMzEyCg==").decode("utf8").strip()


def upload(filename, name=None):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç RDF-—Ñ–∞–π–ª –Ω–∞ —Å–µ—Ä–≤–µ—Ä.

    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
    - filename: –õ–æ–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
    - name: –ò–º—è —Ñ–∞–π–ª–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    """
    if name is None:
        name = filename
    with open(filename, "rb") as inp:
        basic = HTTPBasicAuth(USER, CRED)
        URL = PUTURL.format(user=USER, filename=filename, name=name)
        print("URL:{}".format(URL))
        # files = {"file": (filename, inp, "text/turtle")}
        rc = rq.put(
            URL,
            # files=files,
            data=inp.read(),
            auth=basic,
        )
        print("RC:", rc)
        return

        sg = str(P.samples)
        print("URL:", sg)
        data = ({
            "new_name":
            sg,
            "graph_name":
            "http://localhost:8890/DAV/home/loader/rdf_sink/import.ttl",
        }, )
        files = {
            "new_name": (None, sg),
            "graph_name": (
                None,
                "http://localhost:8890/DAV/home/loader/rdf_sink/import.ttl",
            ),
        }
        rc = rq.post(
            "http://ktulhu.isclan.ru:8890/conductor/graphs_page.vspx?page=1",
            files=files,
            # auth=basic
        )
        print("RC:", rc)


if __name__ == "__main__":
    if 1:
        for file, comp in FILES.items():
            parse_xl(file, comp)
            break
        # update(G)
        target = os.path.join(ONTODIR,TARGET)
        with open(target, "w") as o:

            # TODO: Shift location to a BNode using SPARQL.
            # o.write(G.serialize(format='turtle'))
            o.write(G.serialize(format="turtle"))
            print("WROTE: {}".format(target))
    # upload(TARGET, "samples.ttl")
    if 0:
        targetmt = os.path.join(ONTODIR, TARGETMT)
        with open(targetmt, "w") as o:
            o.write(GMT.serialize(format="turtle"))
    print("#!INFO: Normal exit")
